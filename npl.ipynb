{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('nlp': venv)"
  },
  "interpreter": {
   "hash": "96cda70d3efc28ba2066c4af487caaa7c2e958e0bfa34c246d16aa217d1786b2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "source": [
    "reading data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   0      joy  \\\n",
       "0  1     fear   \n",
       "1  2    anger   \n",
       "2  3  sadness   \n",
       "3  4  disgust   \n",
       "4  5    shame   \n",
       "\n",
       "  On days when I feel close to my partner and other friends.   \\nWhen I feel at peace with myself and also experience a close  \\ncontact with people whom I regard greatly.  \n",
       "0  Every time I imagine that someone I love or I ...                                                                                                                         \n",
       "1  When I had been obviously unjustly treated and...                                                                                                                         \n",
       "2  When I think about the short time that we live...                                                                                                                         \n",
       "3  At a gathering I found myself involuntarily si...                                                                                                                         \n",
       "4  When I realized that I was directing the feeli...                                                                                                                         "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>joy</th>\n      <th>On days when I feel close to my partner and other friends.   \\nWhen I feel at peace with myself and also experience a close  \\ncontact with people whom I regard greatly.</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>fear</td>\n      <td>Every time I imagine that someone I love or I ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>anger</td>\n      <td>When I had been obviously unjustly treated and...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>sadness</td>\n      <td>When I think about the short time that we live...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>disgust</td>\n      <td>At a gathering I found myself involuntarily si...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>shame</td>\n      <td>When I realized that I was directing the feeli...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 85
    }
   ],
   "source": [
    "emotion_df = pd.read_csv(\"1-P-3-ISEAR.csv\")\n",
    "emotion_df.head()"
   ]
  },
  {
   "source": [
    "adding name to column"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_df.columns = ['sn','Target','Sentence']\n",
    "emotion_df.drop('sn',inplace=True,axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    Target                                           Sentence\n",
       "0     fear  Every time I imagine that someone I love or I ...\n",
       "1    anger  When I had been obviously unjustly treated and...\n",
       "2  sadness  When I think about the short time that we live...\n",
       "3  disgust  At a gathering I found myself involuntarily si...\n",
       "4    shame  When I realized that I was directing the feeli..."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Target</th>\n      <th>Sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>fear</td>\n      <td>Every time I imagine that someone I love or I ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>anger</td>\n      <td>When I had been obviously unjustly treated and...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>sadness</td>\n      <td>When I think about the short time that we live...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>disgust</td>\n      <td>At a gathering I found myself involuntarily si...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>shame</td>\n      <td>When I realized that I was directing the feeli...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 87
    }
   ],
   "source": [
    "emotion_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "joy        1081\n",
       "sadness    1074\n",
       "anger      1069\n",
       "fear       1063\n",
       "disgust    1059\n",
       "shame      1059\n",
       "guilt      1040\n",
       "Name: Target, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 88
    }
   ],
   "source": [
    "emotion_df['Target'].value_counts()"
   ]
  },
  {
   "source": [
    "the data looks fairly balance"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Text Preprocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "converting all sentences to lower case"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowercase(text):\n",
    "    '''a function lowercasing all characters'''\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "emotion_df['Sentence'] = emotion_df['Sentence'].apply(lowercase)"
   ]
  },
  {
   "source": [
    "removing punctuation and number from sentences"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def remove_punct_num(text):\n",
    "    '''a function for removing punctuation and number'''\n",
    "    text = \"\".join([char for char in text if char not in string.punctuation and not char.isdigit()])\n",
    "    return text\n",
    "\n",
    "\n",
    "emotion_df['Sentence'] = emotion_df['Sentence'].apply(remove_punct_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    Target                                           Sentence\n",
       "0     fear  every time i imagine that someone i love or i ...\n",
       "1    anger  when i had been obviously unjustly treated and...\n",
       "2  sadness  when i think about the short time that we live...\n",
       "3  disgust  at a gathering i found myself involuntarily si...\n",
       "4    shame  when i realized that i was directing the feeli..."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Target</th>\n      <th>Sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>fear</td>\n      <td>every time i imagine that someone i love or i ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>anger</td>\n      <td>when i had been obviously unjustly treated and...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>sadness</td>\n      <td>when i think about the short time that we live...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>disgust</td>\n      <td>at a gathering i found myself involuntarily si...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>shame</td>\n      <td>when i realized that i was directing the feeli...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 91
    }
   ],
   "source": [
    "emotion_df.head()"
   ]
  },
  {
   "source": [
    "removing all stopwords"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/araul/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_stopwords(text):\n",
    "    \"\"\"\n",
    "    Removing stopwords belonging to english language\n",
    "    \"\"\"\n",
    "    text = [w for w in text.split() if w not in stopwords.words('english')]\n",
    "    return ' '.join(text)\n",
    "\n",
    "emotion_df['Sentence'] = emotion_df['Sentence'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    Target                                           Sentence\n",
       "0     fear  every time imagine someone love could contact ...\n",
       "1    anger  obviously unjustly treated possibility elucida...\n",
       "2  sadness  think short time live relate periods life thin...\n",
       "3  disgust  gathering found involuntarily sitting next two...\n",
       "4    shame  realized directing feelings discontent partner..."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Target</th>\n      <th>Sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>fear</td>\n      <td>every time imagine someone love could contact ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>anger</td>\n      <td>obviously unjustly treated possibility elucida...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>sadness</td>\n      <td>think short time live relate periods life thin...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>disgust</td>\n      <td>gathering found involuntarily sitting next two...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>shame</td>\n      <td>realized directing feelings discontent partner...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 94
    }
   ],
   "source": [
    "emotion_df.head()"
   ]
  },
  {
   "source": [
    "Lemmatization i.e changing words into it's root form"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/araul/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize(text):\n",
    "    text = [lemmatizer.lemmatize(word) for word in text.split()]\n",
    "    return ' '.join(text)\n",
    "\n",
    "emotion_df['Sentence'] = emotion_df['Sentence'].apply(lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    Target                                           Sentence\n",
       "0     fear  every time imagine someone love could contact ...\n",
       "1    anger  obviously unjustly treated possibility elucida...\n",
       "2  sadness  think short time live relate period life think...\n",
       "3  disgust  gathering found involuntarily sitting next two...\n",
       "4    shame  realized directing feeling discontent partner ..."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Target</th>\n      <th>Sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>fear</td>\n      <td>every time imagine someone love could contact ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>anger</td>\n      <td>obviously unjustly treated possibility elucida...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>sadness</td>\n      <td>think short time live relate period life think...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>disgust</td>\n      <td>gathering found involuntarily sitting next two...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>shame</td>\n      <td>realized directing feeling discontent partner ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 97
    }
   ],
   "source": [
    "emotion_df.head()"
   ]
  },
  {
   "source": [
    "spliting data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = emotion_df['Sentence']\n",
    "y = emotion_df['Target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,random_state=10)\n"
   ]
  },
  {
   "source": [
    "TFIDF \n",
    "\n",
    "It is technique to transform text into a meaningful vector of numbers.\n",
    "TFIDF penalizes words that come up too often and don't really have much use. \n",
    "So it rescales the frequency of words that are common which makes scoring more balanced"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(min_df=2, max_df=0.5, ngram_range=(1, 2))\n",
    "train_tfidf = tfidf.fit_transform(X_train)\n",
    "test_tfidf = tfidf.transform(X_test)"
   ]
  },
  {
   "source": [
    "### Model Building"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.8586299529885829, 0.5789120214909335)"
      ]
     },
     "metadata": {},
     "execution_count": 101
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(train_tfidf,y_train)\n",
    "lr.score(train_tfidf, y_train), lr.score(test_tfidf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.8404969778374748, 0.5674949630624581)"
      ]
     },
     "metadata": {},
     "execution_count": 102
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(train_tfidf,y_train)\n",
    "nb.score(train_tfidf, y_train), nb.score(test_tfidf, y_test)"
   ]
  },
  {
   "source": [
    "Test prediction of random sentence"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['sadness'], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 103
    }
   ],
   "source": [
    "test_sentence = ['i am very disappointed at you']\n",
    "test_sentence = tfidf.transform(test_sentence)\n",
    "\n",
    "lr.predict(test_sentence)\n"
   ]
  }
 ]
}