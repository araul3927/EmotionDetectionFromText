{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('nlp': venv)"
  },
  "interpreter": {
   "hash": "96cda70d3efc28ba2066c4af487caaa7c2e958e0bfa34c246d16aa217d1786b2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "reading data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   0        1                                                  2\n",
       "0  0      joy  On days when I feel close to my partner and ot...\n",
       "1  1     fear  Every time I imagine that someone I love or I ...\n",
       "2  2    anger  When I had been obviously unjustly treated and...\n",
       "3  3  sadness  When I think about the short time that we live...\n",
       "4  4  disgust  At a gathering I found myself involuntarily si..."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>joy</td>\n      <td>On days when I feel close to my partner and ot...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>fear</td>\n      <td>Every time I imagine that someone I love or I ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>anger</td>\n      <td>When I had been obviously unjustly treated and...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>sadness</td>\n      <td>When I think about the short time that we live...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>disgust</td>\n      <td>At a gathering I found myself involuntarily si...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 160
    }
   ],
   "source": [
    "emotion_df = pd.read_csv(\"1-P-3-ISEAR.csv\",header=None)\n",
    "emotion_df.head()"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "adding name to column"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_df.columns = ['sn','Target','Sentence']\n",
    "emotion_df.drop('sn',inplace=True,axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    Target                                           Sentence\n",
       "0      joy  On days when I feel close to my partner and ot...\n",
       "1     fear  Every time I imagine that someone I love or I ...\n",
       "2    anger  When I had been obviously unjustly treated and...\n",
       "3  sadness  When I think about the short time that we live...\n",
       "4  disgust  At a gathering I found myself involuntarily si..."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Target</th>\n      <th>Sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>joy</td>\n      <td>On days when I feel close to my partner and ot...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>fear</td>\n      <td>Every time I imagine that someone I love or I ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>anger</td>\n      <td>When I had been obviously unjustly treated and...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>sadness</td>\n      <td>When I think about the short time that we live...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>disgust</td>\n      <td>At a gathering I found myself involuntarily si...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 162
    }
   ],
   "source": [
    "emotion_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "joy        1082\n",
       "sadness    1074\n",
       "anger      1069\n",
       "fear       1063\n",
       "shame      1059\n",
       "disgust    1059\n",
       "guilt      1040\n",
       "Name: Target, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 163
    }
   ],
   "source": [
    "emotion_df['Target'].value_counts()"
   ]
  },
  {
   "source": [
    "the data looks fairly balance"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "checking for duplicate"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "metadata": {},
     "execution_count": 164
    }
   ],
   "source": [
    "emotion_df.duplicated().sum()"
   ]
  },
  {
   "source": [
    "removing duplicate"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_df.drop_duplicates(inplace = True)"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Text Preprocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "converting all sentences to lower case"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowercase(text):\n",
    "    '''a function lowercasing all characters'''\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "emotion_df['Sentence'] = emotion_df['Sentence'].apply(lowercase)"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "removing punctuation and number from sentences"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def remove_punct_num(text):\n",
    "    '''a function for removing punctuation and number'''\n",
    "    text = \"\".join([char for char in text if char not in string.punctuation and not char.isdigit()])\n",
    "    return text\n",
    "\n",
    "\n",
    "emotion_df['Sentence'] = emotion_df['Sentence'].apply(remove_punct_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    Target                                           Sentence\n",
       "0      joy  on days when i feel close to my partner and ot...\n",
       "1     fear  every time i imagine that someone i love or i ...\n",
       "2    anger  when i had been obviously unjustly treated and...\n",
       "3  sadness  when i think about the short time that we live...\n",
       "4  disgust  at a gathering i found myself involuntarily si..."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Target</th>\n      <th>Sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>joy</td>\n      <td>on days when i feel close to my partner and ot...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>fear</td>\n      <td>every time i imagine that someone i love or i ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>anger</td>\n      <td>when i had been obviously unjustly treated and...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>sadness</td>\n      <td>when i think about the short time that we live...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>disgust</td>\n      <td>at a gathering i found myself involuntarily si...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 168
    }
   ],
   "source": [
    "emotion_df.head()"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "removing all stopwords"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/araul/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_stopwords(text):\n",
    "    \"\"\"\n",
    "    Removing stopwords belonging to english language\n",
    "    \"\"\"\n",
    "    text = [w for w in text.split() if w not in stopwords.words('english')]\n",
    "    return ' '.join(text)\n",
    "\n",
    "emotion_df['Sentence'] = emotion_df['Sentence'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    Target                                           Sentence\n",
       "0      joy  days feel close partner friends feel peace als...\n",
       "1     fear  every time imagine someone love could contact ...\n",
       "2    anger  obviously unjustly treated possibility elucida...\n",
       "3  sadness  think short time live relate periods life thin...\n",
       "4  disgust  gathering found involuntarily sitting next two..."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Target</th>\n      <th>Sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>joy</td>\n      <td>days feel close partner friends feel peace als...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>fear</td>\n      <td>every time imagine someone love could contact ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>anger</td>\n      <td>obviously unjustly treated possibility elucida...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>sadness</td>\n      <td>think short time live relate periods life thin...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>disgust</td>\n      <td>gathering found involuntarily sitting next two...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 171
    }
   ],
   "source": [
    "emotion_df.head()"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Lemmatization i.e changing words into it's root form e.g eating to eat"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/araul/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# def lemmatize(text):\n",
    "#     text = [lemmatizer.lemmatize(word,'v') for word in text.split()]\n",
    "#     return ' '.join(text)\n",
    "\n",
    "# emotion_df['Sentence'] = emotion_df['Sentence'].apply(lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag,word_tokenize\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize(text):\n",
    "    \"\"\"\n",
    "    converting words to it's root form\n",
    "    \"\"\"\n",
    "    tmp_txt = []\n",
    "    for token,tag in pos_tag(word_tokenize(text)):\n",
    "        pos=tag[0].lower()\n",
    "            \n",
    "        if pos not in ['a', 'r', 'n', 'v']:\n",
    "            pos='n'\n",
    "        \n",
    "        tmp_txt.append(lemmatizer.lemmatize(token,pos))\n",
    "    return ' '.join(tmp_txt)\n",
    "\n",
    "emotion_df['Sentence'] = emotion_df['Sentence'].apply(lemmatize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    Target                                           Sentence\n",
       "0      joy  day feel close partner friend feel peace also ...\n",
       "1     fear  every time imagine someone love could contact ...\n",
       "2    anger     obviously unjustly treat possibility elucidate\n",
       "3  sadness  think short time live relate period life think...\n",
       "4  disgust  gather find involuntarily sit next two people ..."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Target</th>\n      <th>Sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>joy</td>\n      <td>day feel close partner friend feel peace also ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>fear</td>\n      <td>every time imagine someone love could contact ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>anger</td>\n      <td>obviously unjustly treat possibility elucidate</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>sadness</td>\n      <td>think short time live relate period life think...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>disgust</td>\n      <td>gather find involuntarily sit next two people ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 175
    }
   ],
   "source": [
    "emotion_df.head()"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "spliting data into train and test set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = emotion_df['Sentence']\n",
    "y = emotion_df['Target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,random_state=10)"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "TFIDF \n",
    "\n",
    "It is technique to transform text into a meaningful vector of numbers.\n",
    "TFIDF penalizes words that come up too often and don't really have much use. \n",
    "So it rescales the frequency of words that are common which makes scoring more balanced"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(ngram_range=(1, 2))\n",
    "train_tfidf = tfidf.fit_transform(X_train)\n",
    "test_tfidf = tfidf.transform(X_test)"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Model Building"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.9389377537212449, 0.5895875591615957)"
      ]
     },
     "metadata": {},
     "execution_count": 179
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(train_tfidf,y_train)\n",
    "lr.score(train_tfidf, y_train), lr.score(test_tfidf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.9573748308525034, 0.5652467883705207)"
      ]
     },
     "metadata": {},
     "execution_count": 180
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(train_tfidf,y_train)\n",
    "nb.score(train_tfidf, y_train), nb.score(test_tfidf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "57.123589294722066\n56.28466894453496\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "kfold = model_selection.StratifiedKFold(n_splits=3,shuffle = True, random_state=123)\n",
    "tfidf_v = TfidfVectorizer(ngram_range=(1, 2))\n",
    "valid_tfidf = tfidf_v.fit_transform(X)\n",
    "\n",
    "# Model logistic regression\n",
    "lr_validation = model_selection.cross_val_score(lr, valid_tfidf, y, cv=kfold)\n",
    "print(lr_validation.mean()*100.0)\n",
    "\n",
    "# Model MultinominalNB\n",
    "nb_validation = model_selection.cross_val_score(nb, valid_tfidf, y, cv=kfold)\n",
    "print(nb_validation.mean()*100.0)"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Test prediction of random sentence"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['joy'], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 182
    }
   ],
   "source": [
    "test_sentence = [\"you are happy\"]\n",
    "test_sentence = tfidf.transform(test_sentence)\n",
    "\n",
    "lr.predict(test_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['./model/tfidf_model.joblib']"
      ]
     },
     "metadata": {},
     "execution_count": 183
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(lr, './model/lr_model.joblib')\n",
    "joblib.dump(nb, './model/nb_model.joblib')\n",
    "joblib.dump(tfidf, './model/tfidf_model.joblib')"
   ]
  }
 ]
}