{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('nlp': venv)"
  },
  "interpreter": {
   "hash": "96cda70d3efc28ba2066c4af487caaa7c2e958e0bfa34c246d16aa217d1786b2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "reading data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   0        1                                                  2\n",
       "0  0      joy  On days when I feel close to my partner and ot...\n",
       "1  1     fear  Every time I imagine that someone I love or I ...\n",
       "2  2    anger  When I had been obviously unjustly treated and...\n",
       "3  3  sadness  When I think about the short time that we live...\n",
       "4  4  disgust  At a gathering I found myself involuntarily si..."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>joy</td>\n      <td>On days when I feel close to my partner and ot...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>fear</td>\n      <td>Every time I imagine that someone I love or I ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>anger</td>\n      <td>When I had been obviously unjustly treated and...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>sadness</td>\n      <td>When I think about the short time that we live...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>disgust</td>\n      <td>At a gathering I found myself involuntarily si...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 108
    }
   ],
   "source": [
    "emotion_df = pd.read_csv(\"1-P-3-ISEAR.csv\",header=None)\n",
    "emotion_df.head()"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "adding name to column"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_df.columns = ['sn','Target','Sentence']\n",
    "emotion_df.drop('sn',inplace=True,axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    Target                                           Sentence\n",
       "0      joy  On days when I feel close to my partner and ot...\n",
       "1     fear  Every time I imagine that someone I love or I ...\n",
       "2    anger  When I had been obviously unjustly treated and...\n",
       "3  sadness  When I think about the short time that we live...\n",
       "4  disgust  At a gathering I found myself involuntarily si..."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Target</th>\n      <th>Sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>joy</td>\n      <td>On days when I feel close to my partner and ot...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>fear</td>\n      <td>Every time I imagine that someone I love or I ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>anger</td>\n      <td>When I had been obviously unjustly treated and...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>sadness</td>\n      <td>When I think about the short time that we live...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>disgust</td>\n      <td>At a gathering I found myself involuntarily si...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 110
    }
   ],
   "source": [
    "emotion_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "joy        1082\n",
       "sadness    1074\n",
       "anger      1069\n",
       "fear       1063\n",
       "disgust    1059\n",
       "shame      1059\n",
       "guilt      1040\n",
       "Name: Target, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 111
    }
   ],
   "source": [
    "emotion_df['Target'].value_counts()"
   ]
  },
  {
   "source": [
    "the data looks fairly balance"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Text Preprocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "converting all sentences to lower case"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowercase(text):\n",
    "    '''a function lowercasing all characters'''\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "emotion_df['Sentence'] = emotion_df['Sentence'].apply(lowercase)"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "removing punctuation and number from sentences"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def remove_punct_num(text):\n",
    "    '''a function for removing punctuation and number'''\n",
    "    text = \"\".join([char for char in text if char not in string.punctuation and not char.isdigit()])\n",
    "    return text\n",
    "\n",
    "\n",
    "emotion_df['Sentence'] = emotion_df['Sentence'].apply(remove_punct_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    Target                                           Sentence\n",
       "0      joy  on days when i feel close to my partner and ot...\n",
       "1     fear  every time i imagine that someone i love or i ...\n",
       "2    anger  when i had been obviously unjustly treated and...\n",
       "3  sadness  when i think about the short time that we live...\n",
       "4  disgust  at a gathering i found myself involuntarily si..."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Target</th>\n      <th>Sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>joy</td>\n      <td>on days when i feel close to my partner and ot...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>fear</td>\n      <td>every time i imagine that someone i love or i ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>anger</td>\n      <td>when i had been obviously unjustly treated and...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>sadness</td>\n      <td>when i think about the short time that we live...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>disgust</td>\n      <td>at a gathering i found myself involuntarily si...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 114
    }
   ],
   "source": [
    "emotion_df.head()"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "removing all stopwords"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/araul/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_stopwords(text):\n",
    "    \"\"\"\n",
    "    Removing stopwords belonging to english language\n",
    "    \"\"\"\n",
    "    text = [w for w in text.split() if w not in stopwords.words('english')]\n",
    "    return ' '.join(text)\n",
    "\n",
    "emotion_df['Sentence'] = emotion_df['Sentence'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    Target                                           Sentence\n",
       "0      joy  days feel close partner friends feel peace als...\n",
       "1     fear  every time imagine someone love could contact ...\n",
       "2    anger  obviously unjustly treated possibility elucida...\n",
       "3  sadness  think short time live relate periods life thin...\n",
       "4  disgust  gathering found involuntarily sitting next two..."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Target</th>\n      <th>Sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>joy</td>\n      <td>days feel close partner friends feel peace als...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>fear</td>\n      <td>every time imagine someone love could contact ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>anger</td>\n      <td>obviously unjustly treated possibility elucida...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>sadness</td>\n      <td>think short time live relate periods life thin...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>disgust</td>\n      <td>gathering found involuntarily sitting next two...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 117
    }
   ],
   "source": [
    "emotion_df.head()"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Lemmatization i.e changing words into it's root form"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/araul/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize(text):\n",
    "    text = [lemmatizer.lemmatize(word) for word in text.split()]\n",
    "    return ' '.join(text)\n",
    "\n",
    "emotion_df['Sentence'] = emotion_df['Sentence'].apply(lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    Target                                           Sentence\n",
       "0      joy  day feel close partner friend feel peace also ...\n",
       "1     fear  every time imagine someone love could contact ...\n",
       "2    anger  obviously unjustly treated possibility elucida...\n",
       "3  sadness  think short time live relate period life think...\n",
       "4  disgust  gathering found involuntarily sitting next two..."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Target</th>\n      <th>Sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>joy</td>\n      <td>day feel close partner friend feel peace also ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>fear</td>\n      <td>every time imagine someone love could contact ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>anger</td>\n      <td>obviously unjustly treated possibility elucida...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>sadness</td>\n      <td>think short time live relate period life think...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>disgust</td>\n      <td>gathering found involuntarily sitting next two...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 120
    }
   ],
   "source": [
    "emotion_df.head()"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "spliting data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = emotion_df['Sentence']\n",
    "y = emotion_df['Target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,random_state=10)\n"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "TFIDF \n",
    "\n",
    "It is technique to transform text into a meaningful vector of numbers.\n",
    "TFIDF penalizes words that come up too often and don't really have much use. \n",
    "So it rescales the frequency of words that are common which makes scoring more balanced"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(min_df=2, max_df=0.5, ngram_range=(1, 2))\n",
    "train_tfidf = tfidf.fit_transform(X_train)\n",
    "test_tfidf = tfidf.transform(X_test)"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Model Building"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.8608126259234385, 0.561744966442953)"
      ]
     },
     "metadata": {},
     "execution_count": 124
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(train_tfidf,y_train)\n",
    "lr.score(train_tfidf, y_train), lr.score(test_tfidf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.8398253861652115, 0.5604026845637584)"
      ]
     },
     "metadata": {},
     "execution_count": 125
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(train_tfidf,y_train)\n",
    "nb.score(train_tfidf, y_train), nb.score(test_tfidf, y_test)"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Test prediction of random sentence"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['sadness'], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 126
    }
   ],
   "source": [
    "test_sentence = ['i am very disappointed at you']\n",
    "test_sentence = tfidf.transform(test_sentence)\n",
    "\n",
    "lr.predict(test_sentence)\n"
   ]
  }
 ]
}